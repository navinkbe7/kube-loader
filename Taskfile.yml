version: '2'

env:
  KUBECONFIG: PATH_TO_KUBECONFIG
  HELM_VERSION: helm_2_14_3
  TILLER_VERSION: v2.14.1
  HELM_RELEASE: scape-goat
  HELM_CHART: scape-goat
  NAMESPACE: kube-loader

tasks:
  bootstrap:
    #By default, tasks will be executed in the directory where the Taskfile is located.
    #But you can easily make the task run in another folder informing dir
    #dir: change/directory
    cmds:
      - echo $KUBECONFIG
      - cmd: kubectl create namespace ${NAMESPACE}
        ignore_error: true
      - cmd: kubectl create clusterrolebinding ${NAMESPACE}-admin --clusterrole=cluster-admin --serviceaccount=${NAMESPACE}:default
        ignore_error: true
      - ${HELM_VERSION} init --tiller-image gcr.io/kubernetes-helm/tiller:${TILLER_VERSION} --tiller-namespace ${NAMESPACE}
      - sleep 30s

  deploy:
    cmds:
      - ${HELM_VERSION} upgrade --install ${HELM_RELEASE} ./charts/${HELM_CHART} --tiller-namespace ${NAMESPACE} --namespace ${NAMESPACE}

  delete:
    cmds:
      - ${HELM_VERSION} delete --purge ${HELM_RELEASE} --tiller-namespace ${NAMESPACE}

  load_cpu:
    cmds:
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- cat /dev/urandom | gzip -9 > /dev/null
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- free

  clear_memory:
    cmds:
      - kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- rm -rf /data/file
      - kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- free

  load_memory:
    cmds:
      - kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- rm -rf /data/file
      - kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- dd if=/dev/zero of=/data/file bs=1M count=256

  increase_replicas:
    cmds:
      - kubectl scale --replicas=3 deployment/${HELM_RELEASE} --namespace ${NAMESPACE}
      - kubectl get deployments -n ${NAMESPACE} ${HELM_RELEASE}

  load_disk:
    cmds:
      - kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- rm -rf /data/file
      - cmd: kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n kube-loader -- dd if=/dev/zero of=/data/file bs=1M count=1900
        ignore_error: true
      - kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- df -h | grep /data

  disk_usage:
    cmds:
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- df -h | grep /data
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- df -i | grep /data

  clean_disk:
    cmds:
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- rm -rf /data/file
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- df -h | grep /data

  clean_inodes:
    cmds:
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- find /data -name '*.tmp'
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- df -i | grep /data

  load_inodes:
    cmds:
      - kubectl exec -t $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- ./scripts/load_inodes.sh
      - kubectl exec $(kubectl get pods -n ${NAMESPACE} | grep -m1 ${HELM_RELEASE}|awk '{ print $1 }') -n ${NAMESPACE} -- df -i /data